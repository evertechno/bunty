"""
streamlit_converter_perfected.py
Streamlit Multi-format Converter â€” High-Fidelity, Structured Output.

Core improvements for "as-is" cloning:
- Unified Element Pipeline: PyMuPDF (fitz) and pdfplumber work together. Text blocks, images, and tables are
  all extracted with their bounding boxes and sorted into a single, sequential list based on their vertical position.
  This ensures elements appear in the correct reading order, just as they do in the PDF.
- Style Preservation: Detects bold and italic text from PDF font flags and preserves them in HTML/DOCX output.
- Robust Table Integration: Tables are no longer appended to the end of a page; they are correctly interleaved
  with text content.
- Image Extraction: Now detects and embeds images from the PDF into the output formats.
"""
import io
import os
import zipfile
import base64
from typing import List, Dict, Any
import streamlit as st
import fitz  # PyMuPDF
import pdfplumber
from bs4 import BeautifulSoup
from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
import pandas as pd
import html
import re

# ----------------------------- #
# Utility / Heuristic Functions #
# -----------------------------
BULLET_CHARS = r"^[\u2022\u2023\u25E6\-\*\â€¢\â€“\â€”]\s*|^\d+[\.\)]\s+"

def is_bullet_line(text: str) -> bool:
    """Checks if a line starts with a common bullet or numbered list pattern."""
    return bool(re.match(BULLET_CHARS, text.strip()))

def choose_heading_levels(unique_sizes: List[float]) -> Dict[float, int]:
    """Maps the largest font sizes to semantic heading levels (h1-h6)."""
    sizes = sorted(list(set(unique_sizes)), reverse=True)
    # Map the top 5 largest font sizes to h1, h2, h3, h4, h5. The rest are paragraphs.
    mapping = {size: i + 1 for i, size in enumerate(sizes[:5])}
    return mapping

# ----------------------------- #
# High-Fidelity PDF Parsing     #
# ----------------------------- #
def parse_pdf_high_fidelity(pdf_bytes: bytes, heading_ratio: float) -> Dict[str, Any]:
    """
    Parses a PDF into a single, sorted list of elements (text, tables, images).

    This function combines fitz for text/images and pdfplumber for tables,
    then sorts all found elements by their top vertical position (y0) to ensure
    a perfect reading order.
    """
    all_font_sizes = []
    # First pass: analyze fonts to build heading detection heuristics
    with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
        for page in doc:
            text_instances = page.get_text("dict").get("blocks", [])
            for block in text_instances:
                if block['type'] == 0:  # Text block
                    for line in block.get("lines", []):
                        for span in line.get("spans", []):
                            all_font_sizes.append(round(span['size'], 2))

    unique_sizes = sorted(list(set(all_font_sizes)), reverse=True)
    font_size_headings = choose_heading_levels(unique_sizes)
    body_font_size = unique_sizes[-1] if unique_sizes else 10.0 # Smallest size is likely body text

    # Second pass: extract all elements with bounding boxes
    pages_out = []
    with pdfplumber.open(io.BytesIO(pdf_bytes)) as pdf:
        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            for i, page in enumerate(pdf.pages):
                fitz_page = doc[i]
                elements = []

                # 1. Extract tables with pdfplumber
                tables = page.extract_tables()
                for table_data in tables:
                    if table_data:
                        # Find table bounds to position it correctly
                        bbox = page.find_tables()[tables.index(table_data)].bbox
                        elements.append({"type": "table", "rows": table_data, "bbox": bbox, "y0": bbox[1]})

                # 2. Extract text blocks and images with fitz
                text_blocks = fitz_page.get_text("dict")["blocks"]
                for block in text_blocks:
                    y0 = block['bbox'][1]
                    if block['type'] == 0: # Text
                        block_text = ""
                        spans_data = []
                        for line in block["lines"]:
                            for span in line["spans"]:
                                text = span['text']
                                size = round(span['size'], 2)
                                is_bold = "bold" in span['font'].lower()
                                is_italic = "italic" in span['font'].lower()
                                spans_data.append({"text": text, "size": size, "bold": is_bold, "italic": is_italic})
                            spans_data.append({"text": "\n", "size": 0, "bold": False, "italic": False}) # Preserve line breaks
                        
                        # Heuristic to classify the whole block
                        block_font_size = max([s['size'] for s in spans_data if s['size'] > 0], default=body_font_size)
                        heading_level = font_size_headings.get(block_font_size, 0)
                        
                        if heading_level > 0:
                            el_type = "heading"
                        elif is_bullet_line("".join(s['text'] for s in spans_data)):
                            el_type = "list_item"
                        else:
                            el_type = "para"

                        elements.append({
                            "type": el_type,
                            "spans": spans_data,
                            "level": heading_level,
                            "bbox": block['bbox'],
                            "y0": y0
                        })

                    elif block['type'] == 1: # Image
                        try:
                            img_bytes = fitz_page.extract_image(block['number'])['image']
                            elements.append({"type": "image", "bytes": img_bytes, "bbox": block['bbox'], "y0": y0})
                        except Exception:
                            continue # Skip if image extraction fails

                # Sort all elements on the page by their vertical position
                sorted_elements = sorted(elements, key=lambda el: el['y0'])
                pages_out.append({"page_number": i + 1, "elements": sorted_elements})

    return {"pages": pages_out, "fontsizes": unique_sizes}


# ----------------------------- #
# Converters: High-Fidelity -> HTML / DOCX / TEXT #
# ----------------------------- #

def perfected_to_html(parsed: dict) -> bytes:
    """Generates clean HTML from the sorted, high-fidelity element list."""
    parts = ['<!doctype html><html><head><meta charset="utf-8"><title>Converted Document</title><style>body{font-family:sans-serif;line-height:1.6;padding:2rem;}img{max-width:100%;height:auto;}table{border-collapse:collapse;margin:1rem 0;width:100%;}td,th{border:1px solid #ccc;padding:8px;text-align:left;}ul{padding-left:20px;}</style></head><body>']
    
    in_list = False
    for page in parsed["pages"]:
        parts.append(f'<div style="page-break-after:always;">')
        
        for el in page["elements"]:
            if el["type"] == "list_item" and not in_list:
                parts.append("<ul>")
                in_list = True
            elif el["type"] != "list_item" and in_list:
                parts.append("</ul>")
                in_list = False

            if el["type"] == "heading":
                text_content = "".join(f"<{ 'b' if s['bold'] else '' }{ 'i' if s['italic'] else '' }>{html.escape(s['text'])}</{ 'i' if s['italic'] else '' }{ 'b' if s['bold'] else '' }>" for s in el["spans"])
                parts.append(f"<h{el['level']}>{text_content.replace(html.escape('\n'), '<br>')}</h{el['level']}>")
            elif el["type"] == "para":
                text_content = "".join(f"<{ 'b' if s['bold'] else '' }{ 'i' if s['italic'] else '' }>{html.escape(s['text'])}</{ 'i' if s['italic'] else '' }{ 'b' if s['bold'] else '' }>" for s in el["spans"])
                parts.append(f"<p>{text_content.replace(html.escape('\n'), '<br>')}</p>")
            elif el["type"] == "list_item":
                text_content = "".join(f"<{ 'b' if s['bold'] else '' }{ 'i' if s['italic'] else '' }>{html.escape(s['text'])}</{ 'i' if s['italic'] else '' }{ 'b' if s['bold'] else '' }>" for s in el["spans"])
                parts.append(f"<li>{text_content.replace(html.escape('\n'), '')}</li>")
            elif el["type"] == "table":
                parts.append("<table>")
                for r_idx, r in enumerate(el["rows"]):
                    tag = "th" if r_idx == 0 else "td"
                    parts.append("<tr>" + "".join(f"<{tag}>{html.escape(str(c) if c is not None else '')}</{tag}>" for c in r) + "</tr>")
                parts.append("</table>")
            elif el["type"] == "image":
                img_b64 = base64.b64encode(el['bytes']).decode('utf-8')
                parts.append(f'<img src="data:image/png;base64,{img_b64}" alt="Extracted Image">')
        
        if in_list: # Close any open list at the end of a page
            parts.append("</ul>")
            in_list = False
        parts.append("</div>")

    parts.append("</body></html>")
    return "\n".join(parts).encode("utf-8")

def perfected_to_docx(parsed: dict) -> bytes:
    """Generates a DOCX file, preserving structure, styles, and images."""
    doc = Document()
    doc.styles['Normal'].font.name = 'Calibri'
    doc.styles['Normal'].font.size = Pt(11)

    for page in parsed["pages"]:
        for el in page["elements"]:
            if el["type"] == "heading":
                p = doc.add_heading(level=el['level'])
                for span in el["spans"]:
                    if span['text'] != '\n':
                        run = p.add_run(span['text'])
                        run.bold = span['bold']
                        run.italic = span['italic']
            elif el["type"] in ("para", "list_item"):
                style = 'List Bullet' if el['type'] == 'list_item' else 'Normal'
                p = doc.add_paragraph(style=style)
                for span in el["spans"]:
                    if span['text'] != '\n':
                        run = p.add_run(span['text'])
                        run.bold = span['bold']
                        run.italic = span['italic']
            elif el["type"] == "table":
                rows, cols = len(el["rows"]), max(len(r) for r in el["rows"]) if el["rows"] else 0
                if rows == 0 or cols == 0: continue
                tbl = doc.add_table(rows=rows, cols=cols, style='Table Grid')
                for r_idx, r_data in enumerate(el["rows"]):
                    for c_idx, c_data in enumerate(r_data):
                        tbl.cell(r_idx, c_idx).text = str(c_data if c_data is not None else "")
            elif el["type"] == "image":
                try:
                    doc.add_picture(io.BytesIO(el['bytes']), width=Inches(6.0))
                except Exception:
                    continue # Skip if image format is not supported by docx

        doc.add_page_break()

    out = io.BytesIO()
    doc.save(out)
    return out.getvalue()
    
def perfected_to_text(parsed: dict) -> bytes:
    """Generates a clean plain text representation."""
    out_lines = []
    for page in parsed["pages"]:
        out_lines.append(f"--- PAGE {page['page_number']} ---")
        for el in page["elements"]:
            if el["type"] == "heading":
                text = "".join(s['text'] for s in el['spans']).strip()
                out_lines.append(f"\n## {text}\n")
            elif el["type"] == "para":
                text = "".join(s['text'] for s in el['spans']).strip()
                out_lines.append(text)
            elif el["type"] == "list_item":
                text = "".join(s['text'] for s in el['spans']).strip()
                out_lines.append(f"- {text}")
            elif el["type"] == "table":
                for r in el["rows"]:
                    out_lines.append("\t".join([str(c) if c is not None else "" for c in r]))
                out_lines.append("") # Spacer
    
    return "\n".join(out_lines).encode("utf-8")

# HTML converters remain largely the same, but can be simplified
def html_to_text_bytes(html_bytes: bytes) -> bytes:
    soup = BeautifulSoup(html_bytes, "html.parser")
    return soup.get_text(separator="\n", strip=True).encode("utf-8")

def html_to_docx_bytes(html_bytes: bytes) -> bytes:
    # This function can be kept from the original or enhanced similarly
    soup = BeautifulSoup(html_bytes, "html.parser")
    doc = Document()
    # Simplified loop for brevity
    for element in soup.find_all(['h1', 'h2', 'h3', 'h4', 'p', 'li', 'table']):
        if element.name.startswith('h'):
            level = int(element.name[1])
            doc.add_heading(element.get_text(strip=True), level=level)
        elif element.name == 'p':
            doc.add_paragraph(element.get_text())
        elif element.name == 'li':
            doc.add_paragraph(element.get_text(strip=True), style='List Bullet')
        elif element.name == 'table':
            rows_data = [[cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])] for row in element.find_all('tr')]
            if not rows_data: continue
            tbl = doc.add_table(rows=len(rows_data), cols=max(len(r) for r in rows_data), style='Table Grid')
            for r_idx, r_data in enumerate(rows_data):
                for c_idx, c_data in enumerate(r_data):
                    tbl.cell(r_idx, c_idx).text = c_data
    out = io.BytesIO()
    doc.save(out)
    return out.getvalue()

# ----------------------------- #
# Streamlit App UI              #
# ----------------------------- #
st.set_page_config(page_title="High-Fidelity Converter", layout="wide", page_icon="ðŸ’Ž")
st.title("ðŸ’Ž High-Fidelity Document Converter")
st.markdown("""
This tool performs a **high-fidelity, structured conversion** of documents. It is designed to be as close to a "clone" as possible by:
- **Integrating and sorting** text, tables, and images by their precise position.
- **Preserving text styles** like **bold** and *italics*.
- **Maintaining the original reading order** for a seamless, predictable output.
""")

with st.sidebar:
    st.header("Conversion Options")
    conversion = st.selectbox("Select Conversion", [
        "PDF â†’ High-Fidelity HTML",
        "PDF â†’ High-Fidelity Word (.docx)",
        "PDF â†’ Plain Text",
        "HTML â†’ Word (.docx)",
        "HTML â†’ Plain Text"
    ])
    workers = st.number_input("Parallel Workers (for bulk uploads)", min_value=1, max_value=8, value=4)
    
    st.markdown("### PDF Engine Tuning")
    heading_ratio = st.slider("Heading Font Sensitivity", 1.0, 1.5, 1.15, 0.01, help="Lower value means more text will be considered a heading. Adjust if headings are missed or text is wrongly marked as a heading.")

uploaded_files = st.file_uploader("Upload PDF or HTML files", type=["pdf", "html"], accept_multiple_files=True)

if not uploaded_files:
    st.info("Upload one or more files to begin the conversion.")
    st.stop()

if st.button(f"ðŸš€ Convert {len(uploaded_files)} File(s)"):
    from concurrent.futures import ThreadPoolExecutor, as_completed
    results = []

    def process_file(uploaded_file):
        name = uploaded_file.name
        content = uploaded_file.read()
        ext = os.path.splitext(name)[1].lower()
        
        try:
            if ext == ".pdf":
                parsed_pdf = parse_pdf_high_fidelity(content, heading_ratio)
                if conversion == "PDF â†’ High-Fidelity HTML":
                    output_bytes = perfected_to_html(parsed_pdf)
                    output_name = f"{os.path.splitext(name)[0]}.html"
                    mime = "text/html"
                elif conversion == "PDF â†’ High-Fidelity Word (.docx)":
                    output_bytes = perfected_to_docx(parsed_pdf)
                    output_name = f"{os.path.splitext(name)[0]}.docx"
                    mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                elif conversion == "PDF â†’ Plain Text":
                    output_bytes = perfected_to_text(parsed_pdf)
                    output_name = f"{os.path.splitext(name)[0]}.txt"
                    mime = "text/plain"
                else:
                    return {"name": name, "error": f"Invalid conversion '{conversion}' for PDF."}
            
            elif ext == ".html":
                if conversion == "HTML â†’ Word (.docx)":
                    output_bytes = html_to_docx_bytes(content)
                    output_name = f"{os.path.splitext(name)[0]}.docx"
                    mime = "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                elif conversion == "HTML â†’ Plain Text":
                    output_bytes = html_to_text_bytes(content)
                    output_name = f"{os.path.splitext(name)[0]}_converted.txt"
                    mime = "text/plain"
                else:
                    return {"name": name, "error": f"Invalid conversion '{conversion}' for HTML."}
            else:
                return {"name": name, "error": "Unsupported file type."}

            return {"name": name, "out_name": output_name, "out_bytes": output_bytes, "mime": mime}
        except Exception as e:
            return {"name": name, "error": f"Processing failed: {str(e)}"}

    progress_bar = st.progress(0)
    status_text = st.empty()
    log_area = st.expander("Conversion Logs", expanded=True)

    with ThreadPoolExecutor(max_workers=workers) as executor:
        future_to_file = {executor.submit(process_file, f): f.name for f in uploaded_files}
        for i, future in enumerate(as_completed(future_to_file)):
            result = future.result()
            if "error" in result:
                log_area.error(f"âœ– Error converting {result['name']}: {result['error']}")
            else:
                log_area.success(f"âœ” Successfully converted {result['name']} to {result['out_name']}")
                results.append(result)
            progress_bar.progress((i + 1) / len(uploaded_files))

    if results:
        status_text.success("All conversions complete!")
        
        # Create ZIP archive for all files
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
            for res in results:
                zf.writestr(res['out_name'], res['out_bytes'])
        zip_buffer.seek(0)
        
        st.download_button(
            label="ðŸ“¥ Download All as .zip",
            data=zip_buffer,
            file_name="converted_files.zip",
            mime="application/zip",
        )
        
        st.markdown("---")
        st.subheader("Individual File Previews & Downloads")
        for res in results:
            with st.expander(f"{res['out_name']} ({len(res['out_bytes']):,} bytes)"):
                st.download_button(
                    label=f"Download {res['out_name']}",
                    data=res['out_bytes'],
                    file_name=res['out_name'],
                    mime=res['mime']
                )
                if "html" in res['mime']:
                    st.components.v1.html(res['out_bytes'].decode(errors='ignore'), height=400, scrolling=True)
                elif "text" in res['mime']:
                    st.text_area("Preview", res['out_bytes'].decode(errors='ignore'), height=300)
    else:
        status_text.error("No files were converted successfully. Please check the logs.")

